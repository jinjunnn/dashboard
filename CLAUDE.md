# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## é¢å¤–å¼ºåˆ¶æ€§å¼€å‘è¦æ±‚

1. é™¤éç”¨æˆ·æ˜ç¡®æŒ‡å®šï¼Œ**ç¦æ­¢ç¼–å†™exampleç¤ºä¾‹ä»£ç **ã€‚
2. é™¤éç”¨æˆ·æ˜ç¡®æŒ‡ç¤ºï¼Œ**ç¦æ­¢ç¼–å†™READMEæ–‡æ¡£**ã€‚
3. æµ‹è¯•åº”**ä¼˜å…ˆåœ¨CLIä¸­ç›´æ¥æ‰§è¡Œ**ï¼Œè€Œä¸æ˜¯å…ˆå†™å¤æ‚çš„æµ‹è¯•æ–‡æ¡£å†æ‰§è¡Œã€‚
4. åªæœ‰åœ¨ç”¨æˆ·æ˜ç¡®è¦æ±‚ç¼–å†™æµ‹è¯•æ–‡æ¡£æ—¶ï¼Œæ‰å…è®¸ç¼–å†™æµ‹è¯•æ–‡æ¡£å¹¶æ®æ­¤è¿›è¡Œæµ‹è¯•ã€‚
5. **ç¦æ­¢ä¿®æ”¹ `/tmp` ç›®å½•ä¸‹çš„ä¸´æ—¶æ–‡ä»¶å’Œæµ‹è¯•æ–‡ä»¶**ï¼Œè¿™äº›æ–‡ä»¶ä¸æ˜¯æ ¸å¿ƒä¸šåŠ¡ä»£ç ï¼Œåªä¸“æ³¨äºä¿®æ”¹æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ä»£ç ã€‚

## âš ï¸ ç»å¯¹å¼ºåˆ¶æ€§ç¦ä»¤

**ğŸš« ç»å¯¹ç¦æ­¢ä»»ä½•å½¢å¼çš„å‘åå…¼å®¹æ€§ä»£ç  ğŸš«**

- **ä¸¥æ ¼ç¦æ­¢**ä»»ä½•å‘åå…¼å®¹çš„ä»£ç ã€æ³¨é‡Šã€æˆ–è®¾è®¡
- **ä¸¥æ ¼ç¦æ­¢**ä¿ç•™æ—§æ¥å£ã€æ—§æ–¹æ³•ã€æ—§å˜é‡å
- **ä¸¥æ ¼ç¦æ­¢**ä½¿ç”¨"å‘åå…¼å®¹"ã€"compatibility"ã€"legacy"ç­‰æœ¯è¯­
- **ä¸¥æ ¼ç¦æ­¢**åˆ›å»ºè¿‡æ¸¡æ€§ä»£ç æˆ–ä¸´æ—¶å…¼å®¹æ–¹æ¡ˆ
- **å¿…é¡»ç›´æ¥åˆ é™¤**æ—§ä»£ç ï¼Œä½¿ç”¨æ–°æ ‡å‡†æ¥å£
- **å¿…é¡»å½»åº•é‡æ„**ï¼Œä¸å…è®¸ä»»ä½•å¦¥åæˆ–æŠ˜ä¸­æ–¹æ¡ˆ

**è¿åæ­¤ç¦ä»¤å°†è¢«è§†ä¸ºä¸¥é‡é”™è¯¯ï¼**

## Code Development Standards

**æ‰€æœ‰ä»£ç ä¿®æ”¹å¿…é¡»éµå¾ªç°ä»£è½¯ä»¶å¼€å‘æ ‡å‡†ï¼š**

### æ ¸å¿ƒåŸåˆ™
1. **å•ä¸€èŒè´£åŸåˆ™ (Single Responsibility Principle)**
   - æ¯ä¸ªç±»ã€æ–¹æ³•åªè´Ÿè´£ä¸€ä¸ªåŠŸèƒ½
   - é¿å…god classå’Œè¶…å¤§æ–¹æ³•
   - åŠŸèƒ½æ¸…æ™°ï¼ŒèŒè´£æ˜ç¡®

2. **å…³æ³¨ç‚¹åˆ†ç¦» (Separation of Concerns)**
   - ä¸šåŠ¡é€»è¾‘ä¸æ•°æ®æŒä¹…åŒ–åˆ†ç¦»
   - è®¡ç®—é€»è¾‘ä¸è¡¨ç¤ºé€»è¾‘åˆ†ç¦»
   - é…ç½®ä¸å®ç°åˆ†ç¦»

3. **ç»Ÿä¸€èŒè´£åŸåˆ™**
   - åŒä¸€ä¸ªèŒè´£ç”±åŒä¸€ä¸ªæ–¹æ³•/ç±»ç»´æŠ¤
   - é¿å…åŠŸèƒ½é‡å¤å®ç°
   - ç»Ÿä¸€å…¥å£ï¼Œç»Ÿä¸€ç®¡ç†

4. **ç°ä»£åŒ–é‡æ„åŸåˆ™**
   - **åœ¨åŸä»£ç åŸºç¡€ä¸Šä¼˜åŒ–å‡çº§**ï¼Œä¸åˆ›å»ºEnhanced/V2ç‰ˆæœ¬
   - **ä¸åšå‘åå…¼å®¹**ï¼Œå½»åº•é‡æ„æ—§ä»£ç 
   - **åˆ é™¤å†—ä½™ä»£ç **ï¼Œä¿æŒæ¶æ„ç®€æ´
   - **ç»Ÿä¸€æ¥å£**ï¼Œé¿å…å¤šå¥—APIå¹¶å­˜

### ç¦æ­¢è¡Œä¸º
- âŒ åˆ›å»ºEnhancedã€V2ã€Legacyç­‰å¤šç‰ˆæœ¬å¹¶å­˜
- âŒ **ç»å¯¹ç¦æ­¢ä»»ä½•å‘åå…¼å®¹çš„å†—ä½™ä»£ç **
- âŒ åŒä¸€åŠŸèƒ½å¤šå¤„å®ç°
- âŒ å¤æ‚çš„ä¼˜å…ˆçº§åˆ¤æ–­é€»è¾‘
- âŒ é‡å¤çš„è®¡ç®—å’Œè¯„åˆ†é€»è¾‘
- âŒ ç»•è¿‡é—®é¢˜æ‰¾è§£å†³æ–¹æ¡ˆï¼Œå¿…é¡»ç›´é¢é—®é¢˜æ ¹æœ¬åŸå› 
- âŒ ç¼–å†™ç®€åŒ–ç‰ˆæœ¬æˆ–ç¤ºä¾‹ä»£ç ï¼Œå¿…é¡»ä¿®æ”¹å®é™…ä¸šåŠ¡ä»£ç 
- âŒ **ç»å¯¹ç¦æ­¢ç¼–å†™ä»»ä½•å‘åå…¼å®¹ä»£ç ï¼Œå¿…é¡»ç›´æ¥ä½¿ç”¨æ–°æ ‡å‡†æ¥å£**
- âŒ **ç»å¯¹ç¦æ­¢ä¿ç•™æ—§æ¥å£ã€æ—§æ–¹æ³•åã€æ—§å˜é‡å**

### å¿…é¡»è¡Œä¸º
- âœ… ç›´æ¥ä¿®æ”¹åŸæœ‰ä»£ç ï¼Œå½»åº•é‡æ„
- âœ… ç»Ÿä¸€å…¥å£å’Œç»Ÿä¸€ç®¡ç†
- âœ… æ¸…æ™°çš„èŒè´£åˆ†å·¥
- âœ… ç®€æ´çš„æ¶æ„è®¾è®¡
- âœ… åˆ é™¤æ‰€æœ‰å†—ä½™é€»è¾‘
- âœ… ä¸¥æ ¼ä½¿ç”¨æ–°æ ‡å‡†ï¼Œæœç»å‘åå…¼å®¹
- âœ… å½»åº•è§£å†³é—®é¢˜ï¼Œä¸ç»•è¿‡æˆ–ç®€åŒ–

## Important Changelog Update Rule

**å®Œæˆä»»ä½•ç¼–ç ä»»åŠ¡åï¼Œå¿…é¡»ç›´æ¥æ›´æ–° `changelog.md`ï¼š**

1. **ç›´æ¥ç¼–è¾‘ changelog.md æ–‡ä»¶**ï¼š
   - è¯»å–å½“å‰ `changelog.md` çš„æœ€æ–°ç‰ˆæœ¬å·ï¼ˆå¦‚ `1.2.7`ï¼‰ï¼Œå°†æœ€åä¸€ä½æ•°å­—åŠ 1ï¼ˆå¦‚å˜ä¸º `1.2.8`ï¼‰
   - åœ¨æ–‡ä»¶é¡¶éƒ¨æ’å…¥æ–°ç‰ˆæœ¬æ¡ç›®ï¼Œä½¿ç”¨**å®Œæ•´æ ¼å¼**åŒ…å«ä¸»è¦å˜æ›´å’ŒæŠ€æœ¯ç»†èŠ‚
   - **ç¦æ­¢åˆ›å»ºPythonè„šæœ¬æ¥ä¿®æ”¹changelog**ï¼Œå¿…é¡»ç›´æ¥ç¼–è¾‘æ–‡ä»¶

2. **Changelogæ ‡å‡†æ ¼å¼è¦æ±‚**ï¼š
```markdown
## [x.x.x] - YYYY-MM-DDï¼šğŸ“ ç®€è¦æè¿°ï¼ˆä½¿ç”¨åˆé€‚çš„emojiï¼‰

### ä¸»è¦å˜æ›´
- **æ ¸å¿ƒæ”¹è¿›ç‚¹1**: è¯¦ç»†æè¿°å˜æ›´å†…å®¹å’Œå½±å“
- **æ ¸å¿ƒæ”¹è¿›ç‚¹2**: è¯¦ç»†æè¿°å˜æ›´å†…å®¹å’Œå½±å“
- **æ ¸å¿ƒæ”¹è¿›ç‚¹3**: è¯¦ç»†æè¿°å˜æ›´å†…å®¹å’Œå½±å“

### æŠ€æœ¯ç»†èŠ‚
- **æ–‡ä»¶1**: å…·ä½“æŠ€æœ¯å®ç°ç»†èŠ‚ï¼Œå‚æ•°é…ç½®ï¼Œæ¶æ„å˜æ›´ç­‰
- **æ–‡ä»¶2**: å…·ä½“æŠ€æœ¯å®ç°ç»†èŠ‚ï¼Œå‚æ•°é…ç½®ï¼Œæ¶æ„å˜æ›´ç­‰
- **å…¶ä»–**: æ€§èƒ½ä¼˜åŒ–ã€å…¼å®¹æ€§ã€æµ‹è¯•è¦†ç›–ç­‰æŠ€æœ¯è¯´æ˜
```

3. **ç‰ˆæœ¬å·é€’å¢è§„åˆ™**ï¼š
   - è¡¥ä¸ç‰ˆæœ¬ï¼ˆç¬¬ä¸‰ä½ï¼‰ï¼šbugä¿®å¤ã€å°ä¼˜åŒ–ã€é‡æ„
   - å°ç‰ˆæœ¬ï¼ˆç¬¬äºŒä½ï¼‰ï¼šæ–°åŠŸèƒ½ã€APIæ›´æ”¹  
   - å¤§ç‰ˆæœ¬ï¼ˆç¬¬ä¸€ä½ï¼‰ï¼šé‡å¤§æ¶æ„å˜æ›´

4. **Emojiä½¿ç”¨æ ‡å‡†**ï¼š
   - ğŸš€ æ–°åŠŸèƒ½å’Œé‡å¤§å‡çº§
   - ğŸ”§ ä¼˜åŒ–å’Œæ”¹è¿›  
   - ğŸ› Bugä¿®å¤
   - âœ… å®Œæˆä»»åŠ¡å’Œæµ‹è¯•
   - ğŸ“ æ–‡æ¡£æ›´æ–°
   - ğŸ¯ æ€§èƒ½ä¼˜åŒ–
   - ğŸ”’ å®‰å…¨ç›¸å…³

## Common Development Commands

### Application Management
```bash
# Start the main FastAPI application
python app.py

# Start the orchestrator (coordinates all system components)
python orchestrator.py

# Run with Docker Compose (recommended for development)
docker-compose up -d

# Quick deployment
./quick_deploy.sh

# Build and deploy with fresh base image
./rebuild_dockerbase_and_deploy.sh
```

### Database Operations
The system uses 5 databases with specific testing patterns defined in GEMINI.md:

**IMPORTANT: Database Separation**
- **Main PostgreSQL Database**: `postgresql://postgres:qadkaq-zegxyc-Xeqme3@localhost:5432/stocks` (legacy tables)
- **Supabase Database**: `http://192.168.18.10:54321` (factors, stock tables with time_key fields)
  - URL: `SUPABASE_URL_NETWORK=http://192.168.18.10:54321`
  - Key: `SUPABASE_SERVICE_ROLE_KEY_NETWORK=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImV4cCI6MTk4MzgxMjk5Nn0.EGIM96RAZx35lJzdJsyH-qQwv8Hdp7fsn3W0YpN81IU`
  - PostgreSQL Direct: `postgresql://postgrest:qadkaq-zegxyc-Xeqme3@192.168.18.10:54322/postgres`

```bash
# Main PostgreSQL connection test  
psql "postgresql://postgres:qadkaq-zegxyc-Xeqme3@localhost:5432/stocks" -c "\conninfo"

# Supabase PostgreSQL connection test (port 54322 for direct DB access)
psql "postgresql://postgres:postgres@127.0.0.1:54322/postgres" -c "\conninfo"

# MongoDB connection test  
mongosh "mongodb://admin:pixdow-2padVi-qewguk@localhost:27017/mongo_db?authSource=admin"

# MongoDB data queries
mongosh "mongodb://admin:pixdow-2padVi-qewguk@localhost:27017/mongo_db?authSource=admin" --eval "db.atomic_knowledge.find({}).limit(5).pretty()"
mongosh "mongodb://admin:pixdow-2padVi-qewguk@localhost:27017/mongo_db?authSource=admin" --eval "db.atomic_knowledge.find({content: /breakout/i}).pretty()"
mongosh "mongodb://admin:pixdow-2padVi-qewguk@localhost:27017/mongo_db?authSource=admin" --eval "db.atomic_knowledge.find({tags: 'breakout_strategy'}).pretty()"

# Redis operations
redis-cli -a "your_password_here"
redis-cli KEYS "*"

# Qdrant vector database (via curl)
curl -X GET "http://localhost:6333/collections" -H "api-key: bUjqem-8wyhpi-kejcuw" | jq '.'

# Qdrant data queries
curl -X POST "http://localhost:6333/collections/memory/points/search" \
  -H "api-key: bUjqem-8wyhpi-kejcuw" \
  -H "Content-Type: application/json" \
  -d '{"vector": [0.1, 0.2, 0.3], "limit": 10}' | jq '.'
  
curl -X POST "http://localhost:6333/collections/memory/points/scroll" \
  -H "api-key: bUjqem-8wyhpi-kejcuw" \
  -H "Content-Type: application/json" \
  -d '{"filter": {"must": [{"key": "tags", "match": {"value": "breakout"}}]}, "limit": 100}' | jq '.'
```

### Python Testing
```bash
# CLI testing pattern for functions
python -c "
import asyncio
from models.postgres_model import User, create_record
async def test():
    print('Test logic executed')
asyncio.run(test())
"

# Syntax and import validation
python -m py_compile <file>
python -c "import <module>"
```

### Scheduled Tasks
```bash
# Run specific schedulers
python scripts/scheduled_tasks/okx_scheduler.py
python scripts/scheduled_tasks/signal_engine_scheduler.py
python scripts/scheduled_tasks/eod_snapshot_scheduler.py
python scripts/scheduled_tasks/snapshot_scheduler.py
```

### Risk Center Testing
```bash
# Risk Engine basic testing
python -c "
from services.risk_center.core.risk_engine import RiskEngine
from services.risk_center.core.redis_state_manager import get_state_manager
from schemas.signal_schema import Signal, Priority, RiskLevel, SignalDirection

# Create risk engine
state_manager = get_state_manager()
risk_engine = RiskEngine(state_manager)

# Create test signal
signal = Signal(
    id='test_001',
    symbol='000001.SZ',
    signal_type='breakout',
    direction=SignalDirection.BULLISH,
    price=15.50,
    confidence=0.85,
    score=0.80,
    priority=Priority.HIGH,
    risk_level=RiskLevel.MEDIUM
)

# Execute risk decision
decision = risk_engine.evaluate_signal_with_context(
    signal, 'breakout_strategy', 1000000.0
)

print(f'Decision: {decision.result}')
if decision.result == 'PASS':
    print(f'Approved amount: {decision.approved_amount}')
    print(f'Approved quantity: {decision.approved_quantity}')
else:
    print(f'Reject reason: {decision.reject_reason}')
"

# Redis state queries
python -c "
from services.risk_center.core.redis_state_manager import get_state_manager

state_manager = get_state_manager()

# Query strategy exposure
exposure = state_manager.get_strategy_exposure('breakout_strategy')
print(f'Strategy exposure: {exposure}')

# Query daily count
count = state_manager.get_daily_buy_count('breakout_strategy')
print(f'Daily buy count: {count}')

# Query total exposure
total = state_manager.get_total_exposure()
print(f'Total exposure: {total}')
"

# Configuration management
python -c "
from services.risk_center.core.config_manager import get_config_manager

config_manager = get_config_manager()
result = config_manager.reload_config()
print(f'Config reload: {result.success}')
if result.errors:
    print(f'Config errors: {result.errors}')
"

# Risk Center comprehensive testing
python tmp/test_risk_center_integration.py
python tmp/test_redis_concurrency.py  
python tmp/test_config_loading.py
```

### Audit service testing
```bash
python -c "
from services.risk_center.services.audit_service import get_audit_service
from datetime import datetime, timedelta

audit_service = get_audit_service()

# Query recent decision logs
end_time = datetime.now()
start_time = end_time - timedelta(hours=24)
logs = audit_service.query_decision_logs(
    start_time=start_time,
    end_time=end_time,
    limit=10
)
print(f'Found {len(logs)} decision logs in last 24 hours')

# Get audit statistics
stats = audit_service.get_audit_statistics(
    start_time=start_time,
    end_time=end_time
)
print(f'Audit stats: {stats}')
"
```

## Architecture Overview

### System Design
This is a **FastAPI-based stock analysis and trading system** with sophisticated multi-database architecture, AI-powered analysis, and event-driven quantitative trading capabilities.

**Core Pattern**: Orchestrator-based coordination with event-driven architecture using `utils.eventbus`.

### Multi-Database Architecture
- **PostgreSQL** - Primary relational data, user management, billing
- **MongoDB** - Analysis results, unstructured trading data  
- **Redis** - Caching, real-time state, time-series data, pub/sub messaging
- **Neo4j** - Relationship graphs, ICT pattern analysis
- **Qdrant** - Vector embeddings for AI analysis

### Key Service Modules

#### AI Analysis Framework (`aigo/`)
Multi-agent architecture with specialized components:
- **Intent Recognition Agent** - Routes user queries to appropriate handlers
- **Stock Analysis Agents** - Deep/general analysis with preprocessing
- **DB Agents** - Coordinator pattern for multi-database operations
- **Framework Components**: Conversation graphs, thinking workflows, ReAct agents
- **Template System**: JSON/YAML-based prompt management with dynamic generation

#### Quantitative Trading (`services/quants/`)
Strategy-based architecture with Redis state management:
- **Base Strategy Class** with confidence scoring and event tracking
- **Concrete Strategies**: Breakout, Bull Run, Realtime Breakout, Trend Pullback
- **Workflow Engine**: Node-based processing (advice â†’ analyze â†’ decision â†’ trade)
- **Top-K Ranking System** for signal filtering and prioritization

#### Signal Detection (`services/signals/` + `signals/`)
Two-tier system:
- **Legacy System** (`signals/`) - Individual signal implementations (MSS, BOS, OB, FVG, SSL)
- **New System v2.0** (`services/signals/`) - Plugin architecture with configuration management, smart caching, event-driven processing

#### Risk Center (`services/risk_center/`) - ğŸ†• å…¨æ–°é¡¹ç›®
**æ ¸å¿ƒåŸåˆ™**: å…¨æ–°ä»£ç æ¶æ„ï¼Œä¸éœ€è¦å‘åå…¼å®¹ï¼Œé‡‡ç”¨ç°ä»£åŒ–è®¾è®¡æ¨¡å¼

Unified risk management and position control system:
- **Risk Engine**: Multi-layered risk checks with P95 < 100ms decision time
- **Position Manager**: Complete position lifecycle management (open/add/reduce/close)
- **Signal-Priority Management**: Four-tier priority system (URGENT/HIGH/MEDIUM/LOW) with differentiated quotas
- **Redis State Manager**: Atomic operations for real-time exposure tracking
- **Audit Service**: Complete decision traceability with Supabase storage
- **ç»Ÿä¸€ä¿¡å·é›†æˆ**: æ ‡å‡†åŒ–æ¥å£æ”¯æŒå¤šç³»ç»Ÿä¿¡å·å…¥å£ï¼ˆquants/digital_currencies/signal_engineï¼‰

**æ¶æ„ç‰¹ç‚¹**:
- ğŸ“ **å…¨æ–°é¡¹ç›®**: æ— å†å²åŒ…è¢±ï¼Œé‡‡ç”¨æœ€æ–°è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µ
- ğŸ”„ **ç»Ÿä¸€ä¿¡å·æ¨¡å‹**: ä½¿ç”¨`schemas/signal_schema.py`ç»Ÿä¸€æ‰€æœ‰ä¿¡å·æ•°æ®ç»“æ„
- ğŸ¯ **ç›´æ¥å¯¼å…¥å¯¹æ¥**: serviceså†…éƒ¨ç›´æ¥importï¼Œæ— éœ€HTTPæ¥å£
- âš¡ **é«˜æ€§èƒ½è®¾è®¡**: P95å†³ç­–æ—¶é—´<100msï¼ŒRedisåŸå­æ“ä½œ
- ğŸ›¡ï¸ **å®Œæ•´é£æ§é“¾**: ä¿¡å·è¯„ä¼°â†’ä»“ä½ç®¡ç†â†’é£é™©æ§åˆ¶â†’å®¡è®¡è¿½è¸ª

#### Digital Currencies (`services/digital_currencies/`)
æ•°å­—è´§å¸äº¤æ˜“ç³»ç»Ÿ:
- **Crypto Signal Generator**: åŸºäºICTåˆ†æçš„ä¿¡å·ç”Ÿæˆç³»ç»Ÿ
- **Strategy Framework**: ç»§æ‰¿BaseStrategyçš„æ•°å­—è´§å¸ç­–ç•¥åŸºç±»
- **Multi-timeframe Analysis**: æ”¯æŒ15M/30M/1Hç­‰å¤šæ—¶é—´çº§åˆ«åˆ†æ
- **Discord Integration**: è‡ªåŠ¨ä¿¡å·æ¨é€å’Œé€šçŸ¥ç³»ç»Ÿ

#### Signal Tracker (`services/signal_tracker/`) - ğŸ†• å…¨æ–°æœåŠ¡
**æ ¸å¿ƒåŠŸèƒ½**: ç›‘æ§å·²ç”Ÿæˆä¿¡å·ï¼Œè¯†åˆ«æ‰§è¡Œæœºä¼š

å®Œæ•´äº¤æ˜“ç”Ÿå‘½å‘¨æœŸç›‘æ§:
- **å»ºä»“æœºä¼š**: å…‘ç°äº¤æ˜“æœºä¼š (REALIZATION)
- **åŠ ä»“æœºä¼š**: åŠ ä»“äº¤æ˜“æœºä¼š (ADDITION) 
- **äºŒæ¬¡å…¥åœº**: ç­–ç•¥çš„ç¬¬äºŒä¹°ç‚¹äº¤æ˜“æœºä¼š (SECONDARY_ENTRY)
- **å‡ä»“ç®¡ç†**: å‡ä»“äº¤æ˜“æœºä¼š, æ­¢ç›ˆäº¤æ˜“æœºä¼š, æ­¢æŸäº¤æ˜“æœºä¼š
- **é€€å‡ºç®¡ç†**: å…¨éƒ¨å¹³ä»“äº¤æ˜“æœºä¼š, ç´§æ€¥é€€å‡ºäº¤æ˜“æœºä¼š
- **è°ƒæ•´ç®¡ç†**: ç­–ç•¥è°ƒæ•´äº¤æ˜“æœºä¼š, é£é™©ç®¡ç†äº¤æ˜“æœºä¼š

**æ¶æ„ç‰¹ç‚¹**:
- ğŸ“ **æœåŠ¡å†…ç»„ä»¶**: éç‹¬ç«‹å¾®æœåŠ¡ï¼Œé›†æˆåœ¨æ•´ä½“servicesæ¶æ„ä¸­
- ğŸš« **æ— ç‹¬ç«‹API**: ä¸æä¾›FastAPIç«¯ç‚¹ï¼Œä¸ä½¿ç”¨app.py/Dockerç­‰å¾®æœåŠ¡ç»„ä»¶
- ğŸ”„ **å¤šç»´é…ç½®**: [ç­–ç•¥Ã—é£é™©ç­‰çº§Ã—ä¼˜å…ˆçº§Ã—ç›‘æ§ç±»å‹]å››ç»´é…ç½®çŸ©é˜µ
- ğŸ¯ **æ’ä»¶åŒ–Tracker**: å¯æ’æ‹”ç›‘æ§æ‰§è¡Œå™¨(ä»·æ ¼çªç ´ã€æˆäº¤é‡å¼‚åŠ¨ã€å‡çº¿äº¤å‰ç­‰)
- âš¡ **Risk Centeré›†æˆ**: ç›´æ¥importå¯¹æ¥ï¼Œä½¿ç”¨åŸç”Ÿæ•°æ®ç±»å’Œæ¥å£

**é‡è¦å¼€å‘çº¦æŸ**:
- âŒ ç¦æ­¢æ·»åŠ app.py, requirements.txt, Dockerfileç­‰å¾®æœåŠ¡éƒ¨ç½²æ–‡ä»¶
- âŒ ç¦æ­¢åˆ›å»ºFastAPIè·¯ç”±å’ŒAPIç«¯ç‚¹
- âŒ ç¦æ­¢æ·»åŠ Dockerç›¸å…³é…ç½®
- âœ… åªå¼€å‘æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ç»„ä»¶å’ŒæœåŠ¡ç±»

### API Structure
Domain-driven route organization:
- `/stock` - Core stock data and analysis results
- `/analysis` - AI-powered analysis endpoints  
- `/quant` - Quantitative strategies and signals
- `/risk` - Risk management and position control endpoints
- `/market` - Market data and news
- `/mcp` - Model Context Protocol integration
- `/billing` - Usage tracking and cost management

### Event-Driven Workflows

**Real-time Trading Pipeline**:
1. Data Ingestion â†’ Redis time-series
2. Signal Detection â†’ Parallel analyzers  
3. Strategy Evaluation â†’ Quantitative processing
4. Risk Control â†’ Multi-layer risk checks and position sizing
5. AI Analysis â†’ LLM-powered decision making
6. Trade Execution â†’ Position management and execution
7. Event Tracking â†’ Comprehensive analytics and audit trails

**AI Analysis Workflow**:
1. Intent Recognition â†’ Route to appropriate agents
2. Multi-database Coordination â†’ Context retrieval
3. Template Processing â†’ Dynamic prompt generation
4. LLM Chain Reasoning â†’ Validation and confidence scoring
5. Structured Output â†’ Formatted results

### Configuration Management
- **Global Config** (`configs/global_config.yaml`) - Environment-specific settings
- **Database Config** (`configs/db_config.py`) - Docker-aware connection management
- **Authentication** - API key management with Redis storage and rate limiting

## Memory Systems

### MCP/Memory Tools
The system provides two complementary memory systems for knowledge management:

#### 1. MCP/Memory - Entity and Relation Memory
**Primary Use Case**: Store and query structured entities and relationships

**When to Use**:
- Storing stock-concept relationships (e.g., "ä¸‰ä¸€é‡å·¥ å±äº å¢¨è„±æ°´ç”µå·¥ç¨‹")
- Building knowledge graphs of industry chains and company relationships
- Managing structured entity data with explicit connections

**Usage Pattern**:
```python
# Store entity relationship
{
    "type": "relation",
    "from": "å¢¨è„±æ°´ç”µå·¥ç¨‹",
    "to": "ä¸‰ä¸€é‡å·¥", 
    "relationType": "å±äº"
}

# Store entity definition
{
    "type": "entity",
    "name": "ä¸‰ä¸€é‡å·¥",
    "entityType": "è‚¡ç¥¨",
    "observations": ["å·¥ç¨‹æœºæ¢°ä¸»æœºå‚ï¼Œå—ç›Šäºå¢¨è„±æ°´ç”µå·¥ç¨‹"]
}
```

**Claude Agent Usage**:
- When user says "è®°å¿†è¿™ä¸ªå®ä½“å…³ç³»" â†’ Use MCP/Memory tool
- When user asks "æŸ¥è¯¢XXçš„å…³ç³»" â†’ Query MCP/Memory for entity relationships
- Best for: Company-concept mappings, industry chains, explicit business relationships

#### 2. OpenMemory - Long-term Knowledge Memory  
**Primary Use Case**: Store comprehensive knowledge with contextual understanding

**When to Use**:
- Storing trading strategies, market analysis insights
- Recording user preferences and learning notes
- Managing complex knowledge with rich metadata and scope-based organization

**Scope-based Architecture** (defined in `schemas/memory_scope_schema.py`):
- **8 Major Domains**: trading_knowledge, project_dev, personal, market_data, system_config, learning_notes, business, stock_info
- **Hierarchical Structure**: Level1.Level2.Level3 (e.g., "trading_knowledge.strategy_core.fibonacci_trading")
- **Intelligent Classification**: Auto-assigns scope based on content analysis

**Usage Pattern**:
```python
# Store trading knowledge
scope = "trading_knowledge.strategy_core.fibonacci_trading"
metadata = {
    "scope": scope,
    "data_type": "structured_knowledge", 
    "tags": ["fibonacci", "retracement", "entry_strategy"],
    "importance": 8,
    "confidence": 0.95
}

# Store stock concept information  
scope = "stock_info.concept_definition.æ–°èƒ½æºæ±½è½¦"
metadata = {
    "scope": scope,
    "data_type": "stock_concept",
    "tags": ["concept", "automotive", "clean_energy"]
}
```

**Claude Agent Usage**:
- When user says "è®°å¿†è¿™ä¸ªçŸ¥è¯†/ç­–ç•¥/åˆ†æ" â†’ Use OpenMemory with appropriate scope
- When user asks "æŸ¥è¯¢å…³äºXXçš„çŸ¥è¯†" â†’ Search OpenMemory with scope filters
- Best for: Complex knowledge, strategies, insights, contextual information

### Memory Tool Selection Guide

**Use MCP/Memory when**:
- Simple entity-relationship pairs
- Building knowledge graphs
- Need explicit relationship types
- Storing structured business connections

**Use OpenMemory when**:
- Rich content with context
- Need hierarchical organization
- Complex metadata requirements
- Long-form knowledge and insights

**Integration Pattern**:
Both systems work together - MCP/Memory for the "what" (entities/relations), OpenMemory for the "how/why" (knowledge/context).

### Memory Command Patterns

```bash
# Test MCP/Memory connectivity
docker ps | grep mcp/memory

# Test OpenMemory system
python -c "
from utils.memory_manager import MemoryManager
import asyncio
async def test():
    mm = MemoryManager()
    print('OpenMemory system ready')
asyncio.run(test())
"

# Query memory status
curl -X GET "http://localhost:6333/collections" -H "api-key: bUjqem-8wyhpi-kejcuw" | jq '.'
```

## MCP Database Structures and Query Strategies

### Complete MCP Configuration
The system has **7 active MCP servers** configured in `/Users/impharaonjin/.config/claude/mcp_servers.json`:
- **openmemory** - Python-based long-term knowledge memory
- **memory** - Docker-based entity-relationship memory 
- **postgres** - PostgreSQL database access
- **redis** - Redis cache and time-series data
- **qdrant** - Vector database for semantic search
- **neo4j** - Graph database for relationship analysis  
- **mongodb** - Document database for knowledge storage

### Database-Specific Data Structures and Optimal Query Methods

#### ğŸ—ƒï¸ PostgreSQL (Supabase) - Structured Business Data
**Connection**: `postgresql://postgrest:qadkaq-zegxyc-Xeqme3@192.168.18.10:54322/postgres`

**Core Tables (16 tables, 1562 signals, 14564 stocks)**:
- **signals** - Trading signal records
  - Fields: `symbol, signal_type, direction, confidence, score, strength, metadata(JSONB)`
  - Indexes: symbol, signal_type, status, direction, priority, risk_level
  - Use for: Signal history analysis, performance statistics, risk assessment
- **stock** - Stock master data  
  - Fields: `symbol, name, market, meta_data(JSONB)`
  - Use for: Stock information lookup, market filtering
- **factors/factor_scores** - Factor analysis data
  - Use for: Quantitative factor analysis, signal scoring
- **positions/position_transactions** - Trading position records
  - Use for: Portfolio analysis, transaction history
- **risk_audit_logs** - Risk management audit trails
  - Use for: Risk decision tracking, compliance reporting

**Query Strategies**:
```sql
-- Signal analysis
SELECT signal_type, COUNT(*), AVG(confidence) FROM signals GROUP BY signal_type;

-- Stock filtering  
SELECT * FROM stock WHERE market = 'Aè‚¡' AND symbol LIKE 'SZ.%';

-- Risk analytics
SELECT * FROM risk_audit_logs WHERE event_type = 'SIGNAL_EVALUATION' ORDER BY timestamp DESC;
```

#### ğŸƒ MongoDB - Knowledge Base and Unstructured Data  
**Connection**: `mongodb://admin:pixdow-2padVi-qewguk@localhost:27017/mongo_db?authSource=admin`

**Collections (915 documents)**:
- **atomic_knowledge** - Trading knowledge repository
  - Structure: `scope, content, tags, metadata, strategy, created_at`
  - Scope hierarchy: `trading_knowledge.pattern_recognition.gap_trading_strategy`
  - Content types: Trading strategies, pattern recognition, technical analysis
  - Tags: Pattern types, indicators, timeframes, market types

**Query Strategies**:
```javascript
// Strategy search
db.atomic_knowledge.find({tags: "breakout_strategy"})

// Pattern analysis
db.atomic_knowledge.find({content: /ç¼ºå£äº¤æ˜“/i})

// Scope-based queries
db.atomic_knowledge.find({level1_scope: "trading_knowledge"})

// Metadata filtering
db.atomic_knowledge.find({"metadata.importance": "high"})
```

#### ğŸ”´ Redis - Time-Series Data and Caching
**Connection**: `redis://:pivfo8-dukCof-biccur@192.168.18.10:6379/0`

**Key Patterns (105,865 keys)**:
- **Time-series metrics**: `metric:A_STOCK:1D:SZ.300994:ema10` (TSDB-TYPE)
- **insight states**: `insight:state:SH.603198:1D`  
- **Stock lists**: `a1_stocks`, `total_stocks`
- **Technical indicators**: EMA, KDJ, ATR, ADX, DI_PLUS, DI_MINUS

**Query Strategies**:
```bash
# Technical indicator queries
redis-cli KEYS "metric:A_STOCK:1D:*:ema10"
redis-cli TS.RANGE metric:A_STOCK:1D:SZ.300994:ema10 - +

# Stock state queries  
redis-cli GET "insight:state:SH.603198:1D"
redis-cli SMEMBERS "a1_stocks"

# Pattern matching
redis-cli KEYS "*kdj*" | head -10
```

#### ğŸŸ£ Qdrant - Vector Database for Semantic Search
**Connection**: `http://localhost:6333` (API Key: `bUjqem-8wyhpi-kejcuw`)

**Current Status**: No collections (empty database)
**Intended Use**: Semantic search, vector similarity, AI-powered retrieval

**Query Strategies** (when populated):
```bash
# Collection management
curl -X GET "http://localhost:6333/collections" -H "api-key: bUjqem-8wyhpi-kejcuw"

# Vector search
curl -X POST "http://localhost:6333/collections/knowledge/points/search" \
  -H "api-key: bUjqem-8wyhpi-kejcuw" \
  -d '{"vector": [0.1, 0.2], "limit": 10}'
```

#### ğŸ”µ Neo4j - Graph Database for Relationships
**Connection**: `bolt://localhost:7687` (neo4j/moDruw-1kynqy-bywqan)

**Graph Structure (47,588 nodes)**:
- **Node Labels**: Signal (trading signals as graph nodes)
- **Relationships**: None currently defined
- **Use Cases**: Signal dependency analysis, relationship discovery

**Signal Node Properties**:
- `symbol` - è‚¡ç¥¨ä»£ç  (e.g., 'SZ.301193', 'SH.600519')
- `type` - ä¿¡å·ç±»å‹ (e.g., 'BULLISH_FVG', 'BEARISH_ENGULFING', 'BULLISH_MSS')
- `time` - ä¿¡å·æ—¶é—´ (ISO 8601æ ¼å¼: '2025-08-18T00:00:00+08:00')
- `level` - æ—¶é—´çº§åˆ« (e.g., '1D')
- `direction` - æ–¹å‘ (1=çœ‹å¤š, -1=çœ‹ç©º)
- `status` - çŠ¶æ€ (e.g., 'created')
- `metadata` - JSONå…ƒæ•°æ® (åŒ…å«confidence, strength, support_level, resistance_levelç­‰)
- `id` - å”¯ä¸€æ ‡è¯†ç¬¦ (UUID)

**Query Strategies**:
```bash
# Neo4jè¿æ¥æµ‹è¯•å’ŒåŸºæœ¬ä¿¡æ¯æŸ¥è¯¢
NEO4J_URI=bolt://localhost:7687 NEO4J_USERNAME=neo4j NEO4J_PASSWORD=moDruw-1kynqy-bywqan /Users/impharaonjin/miniconda3/bin/python -c "
from neo4j import GraphDatabase
driver = GraphDatabase.driver('bolt://localhost:7687', auth=('neo4j', 'moDruw-1kynqy-bywqan'))
with driver.session() as session:
    # æŸ¥çœ‹æ€»èŠ‚ç‚¹æ•°
    result = session.run('MATCH (n:Signal) RETURN count(n) as total_nodes')
    total_nodes = result.single()['total_nodes']
    print(f'æ€»SignalèŠ‚ç‚¹æ•°: {total_nodes}')
    
    # æŸ¥è¯¢ç‰¹å®šè‚¡ç¥¨çš„ä¿¡å·
    result = session.run('MATCH (s:Signal) WHERE s.symbol = \"SZ.301193\" RETURN s ORDER BY s.time DESC LIMIT 10')
    signals = list(result)
    print(f'æ‰¾åˆ°SZ.301193çš„ä¿¡å·æ•°é‡: {len(signals)}')
    
    for i, record in enumerate(signals):
        signal = record['s']
        print(f'ä¿¡å·{i+1}: ç±»å‹={signal[\"type\"]}, æ—¶é—´={signal[\"time\"]}, æ–¹å‘={signal[\"direction\"]}')
        
driver.close()
"

# æŸ¥è¯¢è‚¡ç¥¨è¿‘æœŸä¿¡å·çš„Cypherè¯­å¥
MATCH (s:Signal) WHERE s.symbol = 'SZ.301193' RETURN s ORDER BY s.time DESC LIMIT 10

# æŒ‰ä¿¡å·ç±»å‹ç»Ÿè®¡
MATCH (s:Signal) RETURN s.type, count(*) as signal_count ORDER BY signal_count DESC

# æŸ¥è¯¢ç‰¹å®šæ—¶é—´èŒƒå›´çš„ä¿¡å·
MATCH (s:Signal) WHERE s.time >= '2025-08-01T00:00:00+08:00' AND s.symbol = 'SZ.301193' RETURN s ORDER BY s.time DESC

# æŸ¥çœ‹ä¿¡å·çš„æ”¯æ’‘é˜»åŠ›ä½ä¿¡æ¯ (ä»metadata JSONä¸­æå–)
MATCH (s:Signal) WHERE s.symbol = 'SZ.301193' 
RETURN s.symbol, s.type, s.time, 
       apoc.convert.fromJsonMap(s.metadata).support_level as support,
       apoc.convert.fromJsonMap(s.metadata).resistance_level as resistance
ORDER BY s.time DESC LIMIT 5
```

#### ğŸ§  Memory Systems - Knowledge Graphs and Entity Relations

**MCP/Memory (Docker)** - Entity-Relationship Storage:
- **Data Format**: JSONL with entity/relation objects
- **Structure**: `{"type": "entity", "name": "ä¸‰ä¸€é‡å·¥", "entityType": "è‚¡ç¥¨"}`
- **Relations**: `{"type": "relation", "from": "å¢¨è„±æ°´ç”µå·¥ç¨‹", "to": "ä¸‰ä¸€é‡å·¥"}`
- **Use Cases**: Stock-concept relationships, industry chain mapping

**OpenMemory (Python)** - Long-term Knowledge Storage:
- **Scope System**: Hierarchical organization (8 major domains)
- **Content Types**: Trading strategies, analysis insights, user preferences  
- **Metadata**: Importance scores, confidence levels, tags
- **Use Cases**: Complex knowledge storage, contextual information retrieval

### Smart Query Selection Guide

#### ğŸ“ˆ **Trading Signal Analysis**
- **PostgreSQL MCP**: Historical analysis, statistics, compliance reporting
- **Neo4j MCP**: Signal relationships, dependency tracking  
- **Redis MCP**: Real-time indicators, current market state

#### ğŸ“š **Knowledge and Strategy Queries**
- **MongoDB MCP**: Trading strategies, pattern recognition, technical knowledge
- **Memory MCP**: Entity relationships, concept mappings, industry chains
- **OpenMemory MCP**: Complex insights, contextual knowledge, user learning

#### ğŸ“Š **Data Analytics and Research**  
- **PostgreSQL MCP**: Structured data analysis, SQL aggregations, joins
- **Redis MCP**: Time-series analysis, real-time metrics, caching
- **Qdrant MCP**: Semantic search, similarity analysis (when populated)

#### ğŸ” **Relationship and Entity Queries**
- **Memory MCP**: Stock-concept relationships, industry mappings
- **Neo4j MCP**: Complex graph relationships, path analysis  
- **MongoDB MCP**: Tag-based knowledge discovery, content relationships

## Development Guidelines

### Core Development Rules (from .cursorrules)
1. **File Operations**: Always edit files directly, avoid displaying code in conversations
2. **Minimal Output**: Only explain what was changed and where
3. **Testing Required**: Every method must pass unit tests using CLI patterns
4. **Documentation Updates**: Update changelog.md with semantic versioning [x.x.x]
5. **Core Code Protection**: Never modify core directories without explicit permission

### Logger Usage Guidelines

**IMPORTANT: å¿…é¡»ä½¿ç”¨ utils ä¸­çš„ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿï¼Œç¦æ­¢ç›´æ¥ä½¿ç”¨ Python logging æ¨¡å—**

#### æ ‡å‡†Loggerå¯¼å…¥å’Œä½¿ç”¨
```python
# æ­£ç¡®çš„Loggerå¯¼å…¥æ–¹å¼
from utils import get_logger

# ä¸ºç‰¹å®šç»„ä»¶åˆ›å»ºä¸“ç”¨Logger
class MyComponent:
    def __init__(self):
        self.logger = get_logger(f"factor_scorer_{self.__class__.__name__}")
        
    def process_data(self):
        try:
            # ä¸šåŠ¡é€»è¾‘
            pass
        except Exception as e:
            # é”™è¯¯æ—¥å¿— - åŒ…å«è¯¦ç»†è°ƒè¯•ä¿¡æ¯
            self.logger.error(f"è¿æ¥å¤±è´¥: {str(e)}, é”™è¯¯ç±»å‹: {type(e).__name__}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {repr(e)}")
            if hasattr(e, '__traceback__'):
                import traceback
                self.logger.error(f"å †æ ˆä¿¡æ¯: {traceback.format_exc()}")
```

#### è°ƒè¯•ä¿¡æ¯æ ‡å‡†æ ¼å¼
è¿æ¥/æ“ä½œå¤±è´¥æ—¶å¿…é¡»è®°å½•ä»¥ä¸‹ä¿¡æ¯ï¼š
- **é”™è¯¯åŸå› **: `str(e)` 
- **é”™è¯¯ç±»å‹**: `type(e).__name__`
- **ä¸Šä¸‹æ–‡ä¿¡æ¯**: ç›¸å…³å‚æ•°ã€çŠ¶æ€
- **å †æ ˆè·Ÿè¸ª**: `traceback.format_exc()` (å¦‚æœéœ€è¦)

#### LoggeråŠŸèƒ½ç‰¹æ€§
- **è‡ªåŠ¨æ–‡ä»¶è¾“å‡º**: æ—¥å¿—è‡ªåŠ¨ä¿å­˜åˆ° `.logs/` ç›®å½•
- **æ–‡ä»¶è½®è½¬**: å•æ–‡ä»¶æœ€å¤§1MBï¼Œä¿ç•™100ä¸ªå¤‡ä»½
- **æ§åˆ¶å°è¾“å‡º**: åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°ä¾¿äºè°ƒè¯•
- **UTF-8ç¼–ç **: æ”¯æŒä¸­æ–‡æ—¥å¿—
- **çº¿ç¨‹å®‰å…¨**: æ”¯æŒå¤šçº¿ç¨‹ç¯å¢ƒ

### Strategy Development Pattern
```python
# Inherit from BaseStrategy with Redis state management
class NewStrategy(BaseStrategy):
    def process(self) -> Dict[str, Any]:
        # Implement with confidence scoring
        # Use event tracking for performance monitoring  
        # Leverage top-K ranking for signal filtering
        pass
```

### AI Agent Development Pattern
```python
# Extend base agent classes
# Use template management for dynamic prompts
# Implement proper error handling and state management
# Leverage multi-database coordination patterns
```

### Signal Development
Choose between:
- **Legacy system** - Simple implementation in `signals/`
- **New plugin system** - Advanced implementation in `services/signals/` with caching and configuration management

### Factor Generation Rules

**å› å­ç”Ÿæˆå¿…é¡»éµå¾ªæ•°å­¦æ¨¡å‹åŸåˆ™ï¼Œä¸¥ç¦ä½¿ç”¨åŒºé—´è¯„åˆ†æ–¹å¼ï¼š**

#### æ ¸å¿ƒåŸåˆ™
1. **æ•°å­¦æ¨¡å‹é©±åŠ¨**ï¼š
   - æ‰€æœ‰å› å­è¯„åˆ†å¿…é¡»åŸºäºæ•°å­¦å‡½æ•°è®¡ç®—
   - ä½¿ç”¨è¿ç»­æ•°å­¦å‡½æ•°ï¼ˆå¦‚é«˜æ–¯ã€Sigmoidã€å³°å€¼å‡½æ•°ç­‰ï¼‰
   - é¿å…åˆ†æ®µå¼åŒºé—´è¯„åˆ†ï¼ˆå¦‚if x > 0.8 return 1.0çš„æ–¹å¼ï¼‰

2. **æ”¯æŒæœºå™¨å­¦ä¹ **ï¼š
   - æ•°å­¦æ¨¡å‹è¾“å‡ºè¿ç»­å€¼ï¼Œä¾¿äºæ¢¯åº¦è®¡ç®—
   - å‚æ•°å¯è°ƒæ•´ï¼Œæ”¯æŒæ¨¡å‹ä¼˜åŒ–
   - å‡½æ•°å¹³æ»‘å¯å¯¼ï¼Œä¾¿äºåå‘ä¼ æ’­

3. **æ ‡å‡†å»ºæ¨¡ç±»å‹**ï¼š
   - **PEAKï¼ˆå³°å€¼å‹ï¼‰**ï¼šé«˜æ–¯åˆ†å¸ƒï¼Œé€‚ç”¨äºæœ€ä¼˜å€¼åœ¨ä¸­é—´çš„åœºæ™¯
   - **BINARYï¼ˆäºŒå€¼å‹ï¼‰**ï¼šé˜ˆå€¼å‡½æ•°ï¼Œé€‚ç”¨äºæ˜ç¡®åˆ†ç±»åœºæ™¯
   - **SIGMOIDï¼ˆSå‹ï¼‰**ï¼šlogisticå‡½æ•°ï¼Œé€‚ç”¨äºæ¸å˜åœºæ™¯
   - **CONTINUOUSï¼ˆè¿ç»­å‹ï¼‰**ï¼šçº¿æ€§æˆ–å¹‚å‡½æ•°ï¼Œé€‚ç”¨äºå•è°ƒå…³ç³»

#### å®ç°è¦æ±‚
```python
# âœ… æ­£ç¡®åšæ³•ï¼šä½¿ç”¨æ•°å­¦æ¨¡å‹
def calculate_gap_score(gap_ratio: float, swing_position: int) -> float:
    """å³°å€¼å‹æ•°å­¦æ¨¡å‹ï¼šgap_ratioå³°å€¼ä¸º5"""
    return MathUtils.gaussian_score(gap_ratio, center=5.0, spread=2.0)

def calculate_trend_score(swing_position: int) -> float:
    """äºŒå€¼å‹æ•°å­¦æ¨¡å‹ï¼šBINARYåˆ†ç±»"""
    return 1.0 if swing_position == 1 else -1.0 if swing_position == -1 else 0.0

# âŒ é”™è¯¯åšæ³•ï¼šåŒºé—´è¯„åˆ†
def bad_calculate_score(value: float) -> float:
    if value > 0.8:
        return 1.0
    elif value > 0.6:
        return 0.8
    elif value > 0.4:
        return 0.6
    else:
        return 0.2  # è¿™ç§åˆ†æ®µè¯„åˆ†æ–¹å¼è¢«ç¦æ­¢
```

#### å»ºæ¨¡é€‰æ‹©æŒ‡å—
- **è·³ç©ºåˆ†æ**ï¼šPEAKå‹ï¼Œå³°å€¼åœ¨ç†æƒ³è·³ç©ºå¹…åº¦
- **è¶‹åŠ¿ç¡®è®¤**ï¼šBINARYå‹ï¼Œæ˜ç¡®å¤šç©ºåˆ†ç±»
- **å®ä½“å¼ºåº¦**ï¼šSIGMOIDå‹ï¼Œå¼ºåº¦æ¸å˜å…³ç³»
- **ä»·æ ¼ä½ç½®**ï¼šCONTINUOUSå‹ï¼Œä½ç½®è¿ç»­æ˜ å°„
- **å½±çº¿åˆ†æ**ï¼šPEAKå‹ï¼Œç†æƒ³å½±çº¿æ¯”ä¾‹ä¸ºå³°å€¼

#### å‚æ•°é…ç½®
- ä½¿ç”¨`services/factor_engine/core/math_utils.py`æä¾›çš„æ•°å­¦å‡½æ•°
- é€šè¿‡`FactorConfig`çš„`modeling_type`å’Œ`parameters`é…ç½®æ¨¡å‹
- é¿å…ç¡¬ç¼–ç é˜ˆå€¼ï¼Œæ”¹ç”¨æ•°å­¦å‡½æ•°å‚æ•°æ§åˆ¶
## ç»Ÿä¸€ä¿¡å·å¯¹æ¥æ¶æ„ (Signal Integration Architecture)

### æ ¸å¿ƒè®¾è®¡åŸåˆ™
- **ç»Ÿä¸€ä¿¡å·æ¨¡å‹**: æ‰€æœ‰ç³»ç»Ÿä½¿ç”¨`schemas/signal_schema.py`ä¸­çš„`Signal`ç±»
- **ç›´æ¥å¯¼å…¥å¯¹æ¥**: serviceså†…éƒ¨é€šè¿‡ç›´æ¥importè¿›è¡Œé›†æˆï¼Œæ— éœ€HTTPæ¥å£
- **æ ‡å‡†åŒ–å¤„ç†æµç¨‹**: ä¿¡å·è¯„ä¼°â†’é£æ§å†³ç­–â†’ä»“ä½ç®¡ç†â†’å®¡è®¡è¿½è¸ª

### ä¿¡å·å…¥å£ç³»ç»Ÿæ”¯æŒ
ç³»ç»Ÿæ”¯æŒå¤šä¸ªä¿¡å·æ¥æºçš„ç»Ÿä¸€å¯¹æ¥ï¼š

1. **`services/quants/`** - é‡åŒ–ç­–ç•¥ç³»ç»Ÿ
   - BaseStrategyåŠå…¶å­ç±»ç­–ç•¥
   - å·¥ä½œæµå¼•æ“èŠ‚ç‚¹ä¿¡å·
   - MongoDBä¿¡å·å­˜å‚¨ç®¡ç†

2. **`services/digital_currencies/`** - æ•°å­—è´§å¸ç³»ç»Ÿ
   - åŠ å¯†è´§å¸ä¿¡å·ç”Ÿæˆå™¨
   - ICTæŠ€æœ¯åˆ†æä¿¡å·
   - Discordé€šçŸ¥é›†æˆ

3. **`services/signal_engine/`** - ä¿¡å·å¼•æ“ç³»ç»Ÿv2.0
   - æ’ä»¶æ¶æ„ä¿¡å·æ£€æµ‹
   - ä»·æ ¼è¡Œä¸ºä¿¡å·ç”Ÿæˆ
   - ç¼“å­˜ä¼˜åŒ–ä¿¡å·å¤„ç†

### ç»Ÿä¸€å¯¹æ¥æ¥å£
```python
from services.risk_center.interfaces.signal_integration_api import (
    get_signal_integration, 
    process_quants_signal,
    process_crypto_signal,
    process_signal_engine_signal
)

# Quantsç³»ç»Ÿå¯¹æ¥
result = await process_quants_signal(signal, "breakout_strategy", 1000000.0)

# æ•°å­—è´§å¸ç³»ç»Ÿå¯¹æ¥  
result = await process_crypto_signal(signal, "crypto_strategy", 500000.0)

# ä¿¡å·å¼•æ“ç³»ç»Ÿå¯¹æ¥
result = await process_signal_engine_signal(signal, "signal_engine_strategy", 800000.0)
```

### Risk Centeræµ‹è¯•å‘½ä»¤
```bash
# Risk CenteråŸºæœ¬åŠŸèƒ½æµ‹è¯•
python -c "
from services.risk_center.interfaces.signal_integration_api import get_signal_integration
from schemas.signal_schema import Signal, SignalDirection, Priority, RiskLevel
import asyncio

async def test():
    integration = get_signal_integration()
    
    # åˆ›å»ºæµ‹è¯•ä¿¡å·
    signal = Signal(
        symbol='000001.SZ',
        signal_type='breakout',
        time_key='2025-08-22 14:30:00',
        level='1D',
        direction=SignalDirection.BULLISH,
        price=15.50,
        confidence=0.85,
        priority=Priority.HIGH,
        risk_level=RiskLevel.MEDIUM
    )
    
    # æµ‹è¯•ä¿¡å·å¤„ç†
    result = await integration.process_signal(signal, 'test_strategy', 1000000.0)
    print(f'å¤„ç†ç»“æœ: {result.success}, æ¶ˆæ¯: {result.message}')
    
    # æµ‹è¯•çŠ¶æ€æŸ¥è¯¢
    status = await integration.get_strategy_status('test_strategy')
    print(f'ç­–ç•¥çŠ¶æ€: {status}')

asyncio.run(test())
"

# Risk Centerå¥åº·æ£€æŸ¥
python -c "
from services.risk_center.interfaces.signal_integration_api import get_signal_integration
import asyncio

async def health_check():
    integration = get_signal_integration()
    health = await integration.get_risk_center_health()
    print(f'Risk CenterçŠ¶æ€: {health}')

asyncio.run(health_check())
"
```

### Example & Test Script Placement Policy

> **All example scripts and test scripts must be placed in the `tmp/` directory.**
>
> - Do **NOT** add example or test scripts to any core application directories (such as `scripts/`, `services/`, `models/`, `routes/`, etc).
> - The `tmp/` directory is reserved for temporary, experimental, and testing code. It is safe to modify or delete.
> - This rule ensures the core project structure remains clean and production-ready.
> - Any violation (placing test/example scripts outside `tmp/`) will be considered a breach of repository policy.

**Example:**

### Testing Commands from GEMINI.md
The project follows specific CLI testing patterns for rapid validation:
- Use `python -c "..."` for quick function tests
- Use `psql`, `mongosh`, `redis-cli` for database connectivity
- Use `curl` with `jq` for API endpoint testing
- Follow async patterns with `asyncio.run()` for async functions

### Docker Development
```bash
# Development with hot reload
docker-compose up -d

# Check logs
docker logs stock-api -f

# Execute commands in container
docker exec -it stock-api python -c "import models.postgres_model"
```

> **å®Œæˆä»»ä½•ç¼–ç ä»»åŠ¡åï¼Œåœ¨ç¼–å†™æ€»ç»“å‰ï¼Œå¿…é¡»æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š**
>
> 1. **è‡ªåŠ¨æ›´æ–° `changelog.md`ï¼š**
>    - è¯»å–å½“å‰ `changelog.md` çš„æœ€æ–°ç‰ˆæœ¬å·ï¼ˆå¦‚ `1.2.3`ï¼‰ï¼Œå°†æœ€åä¸€ä½æ•°å­—åŠ 1ï¼ˆå¦‚å˜ä¸º `1.2.4`ï¼‰ã€‚
>    - åœ¨æ–°ç‰ˆæœ¬å·ä¸‹æ·»åŠ æœ¬æ¬¡å˜æ›´çš„ç®€è¦æè¿°ã€‚
>    - ç¤ºä¾‹è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆå¯æ”¾åœ¨ `tmp/` ç›®å½•ï¼‰ï¼š
>      ```python
>      import re
>      changelog = "changelog.md"
>      with open(changelog, "r+", encoding="utf-8") as f:
>          content = f.read()
>          m = re.search(r"(\d+\.\d+\.\d+)", content)
>          if m:
>              version = m.group(1)
>              parts = version.split(".")
>              parts[-1] = str(int(parts[-1]) + 1)
>              new_version = ".".join(parts)
>              entry = f"\n## {new_version}\n- æœ¬æ¬¡å˜æ›´ç®€è¿°\n"
>              content = content.replace(version, new_version, 1)
>              content = entry + content
>              f.seek(0)
>              f.write(content)
>      ```
>    - è¯·æ ¹æ®å®é™…å˜æ›´å†…å®¹è¡¥å……æè¿°ã€‚
>
> 1. **Add a clear update entry to `changelog.md`** describing the changes made.
> 2. **Run lint checks** to ensure there are no linting errors in the codebase.
>
> This process is mandatory for all code contributions to maintain project quality and traceability.


## Specs Documentation Standards

### è§„èŒƒåŒ–æ–‡æ¡£ç»“æ„è¦æ±‚

**æ‰€æœ‰æ–°åŠŸèƒ½å’Œéœ€æ±‚å¿…é¡»åœ¨ `specs/` ç›®å½•ä¸‹è¿›è¡Œæ ‡å‡†åŒ–æ–‡æ¡£ç¼–å†™ï¼š**

#### 1. ç›®å½•ç»„ç»‡è§„èŒƒ
- **æœåŠ¡çº§æ–‡æ¡£**: `specs/services/[service-name]/`
- **åŠŸèƒ½çº§æ–‡æ¡£**: `specs/services/[service-name]/[feature-name]/`
- **æ¯ä¸ªåŠŸèƒ½å¿…é¡»ç‹¬ç«‹æ–‡ä»¶å¤¹**: é¿å…åŠŸèƒ½æ–‡æ¡£æ··åˆåœ¨åŒä¸€ç›®å½•

#### 2. æ ‡å‡†æ–‡æ¡£ç»“æ„
æ¯ä¸ªåŠŸèƒ½æ–‡ä»¶å¤¹å¿…é¡»åŒ…å«ä»¥ä¸‹æ ‡å‡†æ–‡æ¡£ï¼š

```
specs/services/[service-name]/[feature-name]/
â”œâ”€â”€ requirements.md     # ç”¨æˆ·éœ€æ±‚è§„æ ¼ä¹¦
â”œâ”€â”€ design.md          # æŠ€æœ¯è®¾è®¡æ–¹æ¡ˆ
â”œâ”€â”€ todolist.md        # åˆ†é˜¶æ®µå®æ–½è®¡åˆ’
â””â”€â”€ README.md          # åŠŸèƒ½æ¦‚è¿°å’ŒçŠ¶æ€è·Ÿè¸ª
```

#### 3. æ–‡æ¡£å†…å®¹è¦æ±‚

**requirements.md - éœ€æ±‚è§„æ ¼ä¹¦**
- é¡¹ç›®æ¦‚è¿°å’ŒèƒŒæ™¯
- ç³»ç»Ÿç°çŠ¶åˆ†æ
- åŠŸèƒ½éœ€æ±‚å’ŒéåŠŸèƒ½éœ€æ±‚
- æŠ€æœ¯çº¦æŸå’Œä¾èµ–
- éªŒæ”¶æ ‡å‡†å’Œé£é™©è¯„ä¼°

**design.md - æŠ€æœ¯è®¾è®¡æ–¹æ¡ˆ**
- æ¶æ„è®¾è®¡å’Œæ•°æ®æµ
- æ ¸å¿ƒç»„ä»¶è®¾è®¡
- APIæ¥å£è®¾è®¡
- æ•°æ®æ¨¡å‹è®¾è®¡
- é…ç½®å’Œéƒ¨ç½²æ–¹æ¡ˆ

**todolist.md - å®æ–½è®¡åˆ’**
- åˆ†é˜¶æ®µå®æ–½roadmapï¼ˆP0/P1/P2ä¼˜å…ˆçº§ï¼‰
- å…·ä½“ä»»åŠ¡æ¸…å•å’Œæ£€æŸ¥ç‚¹
- å·¥æœŸä¼°ç®—å’Œé£é™©ç¼“è§£
- éªŒæ”¶æ ‡å‡†å’Œæµ‹è¯•è®¡åˆ’

**README.md - åŠŸèƒ½æ¦‚è¿°**
- åŠŸèƒ½ç®€ä»‹å’Œæ ¸å¿ƒä»·å€¼
- å½“å‰å¼€å‘çŠ¶æ€
- å·²å®Œæˆçš„é‡Œç¨‹ç¢‘
- ä¸‹ä¸€æ­¥è®¡åˆ’

#### 4. README.md åŒæ­¥æ›´æ–°è¦æ±‚

**å¼ºåˆ¶æ€§è§„åˆ™**: å®Œæˆä»»ä½•æ–°åŠŸèƒ½éœ€æ±‚æ–‡æ¡£åï¼Œå¿…é¡»ç«‹å³æ›´æ–°å¯¹åº”çš„ README.md

- **æœåŠ¡çº§README**: `specs/services/[service-name]/README.md`
- **åŠŸèƒ½å®Œæˆå**: åœ¨READMEä¸­æ ‡è®°åŠŸèƒ½çŠ¶æ€ä¸º"å·²å®Œæˆ"æˆ–"å¼€å‘ä¸­"
- **é‡Œç¨‹ç¢‘è®°å½•**: æ›´æ–°é‡è¦é‡Œç¨‹ç¢‘å’Œå®Œæˆæ—¶é—´
- **æ–‡æ¡£ç´¢å¼•**: æä¾›åŠŸèƒ½æ–‡æ¡£çš„å¿«é€Ÿå¯¼èˆªé“¾æ¥

#### 5. æ–‡æ¡£ç¤ºä¾‹ç»“æ„

```markdown
# Service Name æœåŠ¡è§„æ ¼æ–‡æ¡£

## åŠŸèƒ½åˆ—è¡¨

### âœ… å·²å®ŒæˆåŠŸèƒ½
- [å› å­é›†æˆç³»ç»Ÿ](./factor-integration/) - 2025-08-26 å®Œæˆè®¾è®¡
  - Requirements: âœ… å·²å®Œæˆ
  - Design: âœ… å·²å®Œæˆ  
  - Implementation: ğŸš§ å¼€å‘ä¸­

### ğŸš§ å¼€å‘ä¸­åŠŸèƒ½
- [æ–°åŠŸèƒ½åç§°](./new-feature/) - é¢„è®¡å®Œæˆæ—¶é—´
  - Requirements: âœ… å·²å®Œæˆ
  - Design: â³ è¿›è¡Œä¸­
  - Implementation: â¸ï¸ æœªå¼€å§‹

### ğŸ“‹ è®¡åˆ’åŠŸèƒ½
- åŠŸèƒ½åç§°3 - è®¡åˆ’å¼€å§‹æ—¶é—´
```

#### 6. æ ‡å‡†åŒ–æµç¨‹

1. **éœ€æ±‚åˆ†æ**: åœ¨é€‚å½“ç›®å½•åˆ›å»ºåŠŸèƒ½æ–‡ä»¶å¤¹
2. **æ–‡æ¡£ç¼–å†™**: æŒ‰ç…§æ ‡å‡†ç»“æ„ç¼–å†™ requirements.md
3. **è®¾è®¡é˜¶æ®µ**: å®Œæˆ design.md æŠ€æœ¯æ–¹æ¡ˆ
4. **è®¡åˆ’åˆ¶å®š**: ç¼–å†™ todolist.md å®æ–½è®¡åˆ’
5. **READMEæ›´æ–°**: âš ï¸ **å¼ºåˆ¶æ­¥éª¤** - æ›´æ–°æœåŠ¡READMEçŠ¶æ€
6. **å®æ–½è·Ÿè¸ª**: å®æ–½è¿‡ç¨‹ä¸­åŒæ­¥æ›´æ–°æ–‡æ¡£çŠ¶æ€

#### 7. è´¨é‡æ ‡å‡†

- **å®Œæ•´æ€§**: æ‰€æœ‰å¿…éœ€æ–‡æ¡£é½å…¨
- **å‡†ç¡®æ€§**: æŠ€æœ¯ç»†èŠ‚å‡†ç¡®ï¼Œæ— é—æ¼å…³é”®ä¿¡æ¯
- **å¯æ“ä½œæ€§**: todolistå…·ä½“å¯æ‰§è¡Œ
- **å¯è¿½æº¯æ€§**: READMEå‡†ç¡®åæ˜ å½“å‰çŠ¶æ€
- **æ—¶æ•ˆæ€§**: æ–‡æ¡£ä¸å®é™…å¼€å‘çŠ¶æ€åŒæ­¥

### Environment Variables
Key configuration variables (set in docker-compose.yml or locally):
- `RUNNING_IN_DOCKER=true` - Enables Docker-specific configurations
- `SERVER_PORT=5002` - Application port
- `MCP_SSE_MOUNT_PATH=/mcp` - MCP server mount path

## Important Files and Directories

### Critical Configuration
- `configs/global_config.yaml` - Main configuration file
- `GEMINI.md` - Development rules and CLI testing patterns
- `.cursorrules` - Strict development guidelines and code protection rules

### Core Application Files  
- `app.py` - FastAPI application with middleware and routing
- `orchestrator.py` - System coordinator and event manager
- `requirements.txt` - Python dependencies

### Key Service Directories
- `aigo/` - AI analysis framework with multi-agent architecture
- `services/quants/` - Quantitative trading strategies and workflow
- `services/signals/` - Signal detection system v2.0
- `services/risk_center/` - Risk management and position control system
- `models/` - Database models for all 5 databases
- `routes/` - FastAPI route handlers organized by domain

### Scripts and Utilities
- `scripts/scheduled_tasks/` - Background job schedulers
- `utils/` - Common utilities including eventbus, logging, Redis client
- `tmp/` - Temporary development and testing scripts (safe to modify)